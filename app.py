from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
import numpy as np
from collections import defaultdict, Counter
import streamlit as st
import re

# --------------------Dictionary --------------------
dictionary = {



    # -------------------------
    # Basic Negative Words
    # -------------------------
    "no": "Ù†Ù‡",
    "not": "Ù†ÛÛŒÚº",
    "never": "Ù‡Ø±Ú¯Ø²",
    "none": "Ù‡ÛŒÚ†",
    "nothing": "Ù‡ÛŒÚ† Ú†ÛŒØ²",
    "nowhere": "Ù‡ÛŒÚ† Ø¬Ø§",
    "neither": "Ù†Ù‡ Ø§ÛŒÙ† Ù†Ù‡ Ø¢Ù†",
    "nor": "Ù†Ù‡",
    "nobody": "Ù‡ÛŒÚ†â€ŒÚ©Ø³",
    "without": "Ø¨Ø¯ÙˆÙ†",
    "fail": "Ø´Ú©Ø³Øª Ø®ÙˆØ±Ø¯Ù†",
    "failure": "Ø´Ú©Ø³Øª",
    "wrong": "Ø§Ø´ØªØ¨Ø§Ù‡",
    "bad": "Ø¨Ø¯",
    "worse": "Ø¨Ø¯ØªØ±",
    "worst": "Ø¨Ø¯ØªØ±ÛŒÙ†",
    "stop": "ØªÙˆÙ‚Ù",
    "impossible": "ØºÛŒØ± Ù…Ù…Ú©Ù†",
    "lack": "Ú©Ù…Ø¨ÙˆØ¯",
    "lost": "Ú¯Ù… Ø´Ø¯Ù‡",

    # -------------------------
    # Negative Verbs
    # -------------------------
    "can't": "Ù†Ù…ÛŒ ØªÙˆØ§Ù†Ù…",
    "cannot": "Ù†Ù…ÛŒ ØªÙˆØ§Ù†Ù…",
    "won't": "Ù†Ø®ÙˆØ§Ù‡Ù…",
    "don't": "Ù†Ú©Ù†",
    "didn't": "Ù†Ú©Ø±Ø¯",
    "isn't": "Ù†ÛŒØ³Øª",
    "aren't": "Ù†ÛŒØ³ØªÙ†Ø¯",
    "wasn't": "Ù†Ø¨ÙˆØ¯",
    "weren't": "Ù†Ø¨ÙˆØ¯Ù†Ø¯",
    "shouldn't": "Ù†Ø¨Ø§ÛŒØ¯",
    "couldn't": "Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø³Øª",
    "doesn't": "Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯",
    "haven't": "Ù†Ø¯Ø§Ø±Ù…",
    "hasn't": "Ù†Ø¯Ø§Ø±Ø¯",
    "hadn't": "Ù†Ø¯Ø§Ø´Øª",
    "avoid": "Ø§Ø¬ØªÙ†Ø§Ø¨ Ú©Ø±Ø¯Ù†",
    "reject": "Ø±Ø¯ Ú©Ø±Ø¯Ù†",

    # -------------------------
    # Negative Emotions
    # -------------------------
    "sad": "ØºÙ…Ú¯ÛŒÙ†",
    "unhappy": "Ù†Ø§Ø±Ø§Ø­Øª",
    "angry": "Ø¹ØµØ¨Ø§Ù†ÛŒ",
    "upset": "Ù†Ø§Ø±Ø§Ø­Øª",
    "hate": "Ù†ÙØ±Øª",
    "fear": "ØªØ±Ø³",
    "scared": "ØªØ±Ø³ÛŒØ¯Ù‡",
    "afraid": "ØªØ±Ø³ÛŒØ¯Ù‡",
    "stress": "Ø§Ø³ØªØ±Ø³",
    "depressed": "Ø§ÙØ³Ø±Ø¯Ù‡",
    "anxious": "Ù†Ú¯Ø±Ø§Ù†",
    "pain": "Ø¯Ø±Ø¯",
    "hurt": "Ø¢Ø²Ø§Ø± Ø¯ÛŒØ¯Ù‡",

    # -------------------------
    # Negative Adjectives
    # -------------------------
    "poor": "Ø¶Ø¹ÛŒÙ",
    "weak": "Ú©Ù…Ø²ÙˆØ±",
    "ugly": "Ø²Ø´Øª",
    "lazy": "ØªÙ†Ø¨Ù„",
    "rude": "Ø¨ÛŒâ€ŒØ§Ø¯Ø¨",
    "fake": "Ø¬Ø¹Ù„ÛŒ",
    "broken": "Ø®Ø±Ø§Ø¨",
    "dangerous": "Ø®Ø·Ø±Ù†Ø§Ú©",
    "negative": "Ù…Ù†ÙÛŒ",
    "hard": "Ø³Ø®Øª",
    "difficult": "Ø¯Ø´ÙˆØ§Ø±",
    "hopeless": "Ø¨ÛŒâ€ŒØ§Ù…ÛŒØ¯",

    # -------------------------
    # Negative Phrases
    # -------------------------
    "not at all": "Ø§ØµÙ„Ø§Ù‹",
    "not really": "Ù†Ù‡ ÙˆØ§Ù‚Ø¹Ø§Ù‹",
    "no way": "Ø¨Ù‡ Ù‡ÛŒÚ† ÙˆØ¬Ù‡",
    "nothing special": "Ú†ÛŒØ² Ø®Ø§ØµÛŒ Ù†ÛŒØ³Øª",
    "not good": "Ø®ÙˆØ¨ Ù†ÛŒØ³Øª",
    "not working": "Ú©Ø§Ø± Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯",
    "out of order": "Ø®Ø±Ø§Ø¨ Ø§Ø³Øª",
    "don't like": "Ø¯ÙˆØ³Øª Ù†Ø¯Ø§Ø±Ù…",
    "don't want": "Ù†Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡Ù…",
    "no choice": "Ù‡ÛŒÚ† Ø§Ù†ØªØ®Ø§Ø¨ÛŒ Ù†ÛŒØ³Øª",
  # Pronouns
    "i": "Ù…Ù†", "you": "ØªÙˆ", "he": "Ø§Ùˆ", "she": "Ø§Ùˆ", "it": "Ø¢Ù†",
    "we": "Ù…Ø§", "they": "Ø¢Ù†Ù‡Ø§",
    "me": "Ù…Ù†", "him": "Ø§Ùˆ", "her": "Ø§Ùˆ", "us": "Ù…Ø§", "them": "Ø¢Ù†Ù‡Ø§",
    "my": "Ù…Ù†", "your": "ØªÙˆ", "his": "Ø§Ùˆ", "our": "Ù…Ø§", "their": "Ø¢Ù†Ù‡Ø§","very":"Ø®ÛŒÙ„ÛŒ",

    # Verbs
    "am": "Ù‡Ø³ØªÙ…", "is": "Ø§Ø³Øª", "are": "Ù‡Ø³ØªÙ†Ø¯", 
    "was": "Ø¨ÙˆØ¯", "were": "Ø¨ÙˆØ¯Ù†Ø¯",
    "have": "Ø¯Ø§Ø´ØªÙ†", "has": "Ø¯Ø§Ø±Ø¯", "had": "Ø¯Ø§Ø´Øª",
    "do": "Ú©Ø±Ø¯Ù†", "does": "Ù…ÛŒâ€ŒÚ©Ù†Ø¯", "did": "Ú©Ø±Ø¯",
    "be": "Ø¨ÙˆØ¯Ù†",
    "say": "Ú¯ÙØªÙ†",
    "get": "Ú¯Ø±ÙØªÙ†",
    "make": "Ø³Ø§Ø®ØªÙ†",
    "go": "Ø±ÙØªÙ†", "went": "Ø±ÙØªÙ…", "goes": "Ù…ÛŒâ€ŒØ±ÙˆØ¯", "going": "Ù…ÛŒâ€ŒØ±ÙˆØ¯",
    "see": "Ø¯ÛŒØ¯Ù†", "saw": "Ø¯ÛŒØ¯Ù…", "seen": "Ø¯ÛŒØ¯Ù‡",
    "take": "Ú¯Ø±ÙØªÙ†",
    "come": "Ø¢Ù…Ø¯Ù†", "came": "Ø¢Ù…Ø¯Ù…",
    "know": "Ø¯Ø§Ù†Ø³ØªÙ†", "knew": "Ø¯Ø§Ù†Ø³ØªÙ…",
    "think": "ÙÚ©Ø± Ú©Ø±Ø¯Ù†", "thought": "ÙÚ©Ø± Ú©Ø±Ø¯Ù…",
    "want": "Ø®ÙˆØ§Ø³ØªÙ†", "wanted": "Ø®ÙˆØ§Ø³ØªÙ…",
    "like": "Ø¯ÙˆØ³Øª Ø¯Ø§Ø´ØªÙ†", "liked": "Ø¯ÙˆØ³Øª Ø¯Ø§Ø´ØªÙ…",
    "love": "Ø¯ÙˆØ³Øª Ø¯Ø§Ø´ØªÙ†", "loved": "Ø¯ÙˆØ³Øª Ø¯Ø§Ø´ØªÙ…",
    "work": "Ú©Ø§Ø± Ú©Ø±Ø¯Ù†", "worked": "Ú©Ø§Ø± Ú©Ø±Ø¯Ù…",
    "play": "Ø¨Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù†", "played": "Ø¨Ø§Ø²ÛŒ Ú©Ø±Ø¯Ù…",
    "read": "Ø®ÙˆØ§Ù†Ø¯Ù†", "reading": "Ù…ÛŒâ€ŒØ®ÙˆØ§Ù†Ø¯",
    "write": "Ù†ÙˆØ´ØªÙ†", "writing": "Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³Ø¯",
    "speak": "ØµØ­Ø¨Øª Ú©Ø±Ø¯Ù†", "speaking": "ØµØ­Ø¨Øª Ù…ÛŒâ€ŒÚ©Ù†Ø¯",
    "understand": "ÙÙ‡Ù…ÛŒØ¯Ù†", "understanding": "Ù…ÛŒâ€ŒÙÙ‡Ù…Ø¯",
    "learn": "ÛŒØ§Ø¯ Ú¯Ø±ÙØªÙ†", "learning": "ÛŒØ§Ø¯ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯",
    "teach": "Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù†", "teaching": "Ø¢Ù…ÙˆØ²Ø´ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯",
    "look": "Ù†Ú¯Ø§Ù‡ Ú©Ø±Ø¯Ù†",
    "give": "Ø¯Ø§Ø¯Ù†",
    "use": "Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ø±Ø¯Ù†",
    "find": "Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù†",
    "tell": "Ú¯ÙØªÙ†",
    "ask": "Ù¾Ø±Ø³ÛŒØ¯Ù†",
    "seem": "Ø¨Ù‡ Ù†Ø¸Ø± Ø±Ø³ÛŒØ¯Ù†",
    "feel": "Ø§Ø­Ø³Ø§Ø³ Ú©Ø±Ø¯Ù†",
    "try": "ØªÙ„Ø§Ø´ Ú©Ø±Ø¯Ù†",
    "leave": "ØªØ±Ú© Ú©Ø±Ø¯Ù†",
    "call": "ØµØ¯Ø§ Ø²Ø¯Ù†",
    "drink": "Ù†ÙˆØ´ÛŒØ¯Ù†",
    "run": "Ø¯ÙˆÛŒØ¯Ù†",
    "live": "Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ø±Ø¯Ù†",
    "move": "Ø­Ø±Ú©Øª Ú©Ø±Ø¯Ù†",
    "study": "Ù…Ø·Ø§Ù„Ø¹Ù‡ Ú©Ø±Ø¯Ù†",
    "start": "Ø´Ø±ÙˆØ¹ Ú©Ø±Ø¯Ù†",
    "stop": "Ù…ØªÙˆÙ‚Ù Ú©Ø±Ø¯Ù†",
    # FIX: Added 'beat', 'kick', 'hate', 'feeling'
    "hate": "Ù†ÙØ±Øª",
    "beat": "Ø²Ø¯Ù†",
    "kick": "Ù„Ú¯Ø¯ Ø²Ø¯Ù†",
    "feeling": "Ø§Ø­Ø³Ø§Ø³",


    # Modal verbs
    "can": "Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù…", "could": "Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø³ØªÙ…",
    "will": "Ø®ÙˆØ§Ù‡Ù…", "would": "Ù…ÛŒâ€ŒÚ©Ø±Ø¯Ù…",
    "shall": "Ø¨Ø§ÛŒØ¯", "should": "Ø¨Ø§ÛŒØ¯",
    "may": "Ù…Ù…Ú©Ù† Ø§Ø³Øª", "might": "Ù…Ù…Ú©Ù† Ø¨ÙˆØ¯",
    "must": "Ø¨Ø§ÛŒØ¯",

    # Nouns
    "time": "Ø²Ù…Ø§Ù†", "person": "Ø´Ø®Øµ", "people": "Ù…Ø±Ø¯Ù…",
    "man": "Ù…Ø±Ø¯", "woman": "Ø²Ù†",
    "child": "Ú©ÙˆØ¯Ú©", "children": "Ú©ÙˆØ¯Ú©Ø§Ù†",
    "family": "Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡",
    "friend": "Ø¯ÙˆØ³Øª",
    "house": "Ø®Ø§Ù†Ù‡", "home": "Ø®Ø§Ù†Ù‡",
    "room": "Ø§ØªØ§Ù‚", "door": "Ø¯Ø±", "window": "Ù¾Ù†Ø¬Ø±Ù‡",
    "car": "Ù…Ø§Ø´ÛŒÙ†", "bus": "Ø§ØªÙˆØ¨ÙˆØ³", "train": "Ù‚Ø·Ø§Ø±", "bike": "Ø¯ÙˆÚ†Ø±Ø®Ù‡",
    "water": "Ø¢Ø¨", "food": "ØºØ°Ø§", "bread": "Ù†Ø§Ù†", "rice": "Ø¨Ø±Ù†Ø¬", "fruit": "Ù…ÛŒÙˆÙ‡",
    "book": "Ú©ØªØ§Ø¨", "pen": "Ù‚Ù„Ù…", "paper": "Ú©Ø§ØºØ°", "computer": "Ú©Ø§Ù…Ù¾ÛŒÙˆØªØ±",
    "phone": "ØªÙ„ÙÙ†", "tv": "ØªÙ„ÙˆÛŒØ²ÛŒÙˆÙ†", "music": "Ù…ÙˆØ³ÛŒÙ‚ÛŒ",
    "school": "Ù…Ø¯Ø±Ø³Ù‡", "teacher": "Ù…Ø¹Ù„Ù…", "student": "Ø¯Ø§Ù†Ø´Ø¬Ùˆ",
    "work": "Ú©Ø§Ø±", "job": "Ø´ØºÙ„", "money": "Ù¾ÙˆÙ„", "price": "Ù‚ÛŒÙ…Øª",
    "city": "Ø´Ù‡Ø±", "country": "Ú©Ø´ÙˆØ±", "world": "Ø¬Ù‡Ø§Ù†",
    "street": "Ø®ÛŒØ§Ø¨Ø§Ù†",
    "day": "Ø±ÙˆØ²", "night": "Ø´Ø¨", "week": "Ù‡ÙØªÙ‡", "month": "Ù…Ø§Ù‡", "year": "Ø³Ø§Ù„",
    "sun": "Ø®ÙˆØ±Ø´ÛŒØ¯", "moon": "Ù…Ø§Ù‡", "star": "Ø³ØªØ§Ø±Ù‡", "sky": "Ø¢Ø³Ù…Ø§Ù†",
    "tree": "Ø¯Ø±Ø®Øª", "flower": "Ú¯Ù„", "animal": "Ø­ÛŒÙˆØ§Ù†",
    "dog": "Ø³Ú¯", "cat": "Ú¯Ø±Ø¨Ù‡", "bird": "Ù¾Ø±Ù†Ø¯Ù‡", "fish": "Ù…Ø§Ù‡ÛŒ",
    "name": "Ù†Ø§Ù…", "word": "Ú©Ù„Ù…Ù‡", "number": "Ø¹Ø¯Ø¯",
    "problem": "Ù…Ø´Ú©Ù„", "fact": "ÙˆØ§Ù‚Ø¹ÛŒØª",
    "way": "Ø±Ø§Ù‡", "thing": "Ú†ÛŒØ²",
    "life": "Ø²Ù†Ø¯Ú¯ÛŒ",
    "hand": "Ø¯Ø³Øª", "eye": "Ú†Ø´Ù…", "head": "Ø³Ø±",
    "place": "Ù…Ú©Ø§Ù†", "point": "Ù†Ù‚Ø·Ù‡",
    "toy": "Ø§Ø³Ø¨Ø§Ø¨ Ø¨Ø§Ø²ÛŒ", # FIX: Added 'toy'
    
    # Adjectives
    "good": "Ø®ÙˆØ¨", "bad": "Ø¨Ø¯",
    "big": "Ø¨Ø²Ø±Ú¯", "small": "Ú©ÙˆÚ†Ú©",
    "beautiful": "Ø²ÛŒØ¨Ø§", "ugly": "Ø²Ø´Øª",
    "happy": "Ø®ÙˆØ´Ø­Ø§Ù„", "sad": "ØºÙ…Ú¯ÛŒÙ†",
    "angry": "Ø¹ØµØ¨Ø§Ù†ÛŒ", "tired": "Ø®Ø³ØªÙ‡", "hungry": "Ú¯Ø±Ø³Ù†Ù‡", "thirsty": "ØªØ´Ù†Ù‡",
    "hot": "Ø¯Ø§Øº", "cold": "Ø³Ø±Ø¯", "warm": "Ú¯Ø±Ù…", "cool": "Ø®Ù†Ú©",
    "new": "Ø¬Ø¯ÛŒØ¯", "old": "Ù‚Ø¯ÛŒÙ…ÛŒ",
    "young": "Ø¬ÙˆØ§Ù†", "fast": "Ø³Ø±ÛŒØ¹", "slow": "Ø¢Ù‡Ø³ØªÙ‡",
    "easy": "Ø¢Ø³Ø§Ù†", "difficult": "Ø³Ø®Øª",
    "important": "Ù…Ù‡Ù…",
    "first": "Ø§ÙˆÙ„ÛŒÙ†", "last": "Ø¢Ø®Ø±ÛŒÙ†",
    "long": "Ø¨Ù„Ù†Ø¯",
    "great": "Ø¹Ø§Ù„ÛŒ",
    "little": "Ú©ÙˆÚ†Ú©",
    "own": "Ù…Ø§Ù„ Ø®ÙˆØ¯",
    "other": "Ø¯ÛŒÚ¯Ø±",
    "high": "Ø¨Ø§Ù„Ø§",
    "different": "Ù…ØªÙØ§ÙˆØª",
    "public": "Ø¹Ù…ÙˆÙ…ÛŒ",
    "red": "Ù‚Ø±Ù…Ø²", "blue": "Ø¢Ø¨ÛŒ", "green": "Ø³Ø¨Ø²",
    "ready": "Ø¢Ù…Ø§Ø¯Ù‡",
    "exhausted": "Ø®Ø³ØªÙ‡", # FIX: Added 'exhausted'
    "dumb": "Ø§Ø­Ù…Ù‚", # FIX: Added 'dumb'


    # Prepositions
    "in": "Ø¯Ø±", "on": "Ø±ÙˆÛŒ", "at": "Ø¯Ø±",
    "to": "Ø¨Ù‡", "from": "Ø§Ø²",
    "with": "Ø¨Ø§", "without": "Ø¨Ø¯ÙˆÙ†",
    "for": "Ø¨Ø±Ø§ÛŒ", "about": "Ø¯Ø±Ø¨Ø§Ø±Ù‡",
    "by": "ØªÙˆØ³Ø·", "of": "Ø§Ø²",
    "up": "Ø¨Ø§Ù„Ø§", "down": "Ù¾Ø§ÛŒÛŒÙ†",
    "out": "Ø¨ÛŒØ±ÙˆÙ†",
    "over": "Ø±ÙˆÛŒ",
    "under": "Ø²ÛŒØ±",

    # Question words
    "what": "Ú†Ù‡", "who": "Ú†Ù‡ Ú©Ø³ÛŒ", "where": "Ú©Ø¬Ø§",
    "when": "Ú©ÛŒ", "why": "Ú†Ø±Ø§",
    "how": "Ú†Ø·ÙˆØ±", "which": "Ú©Ø¯Ø§Ù…",

    # Common phrases/Other words
    "hello": "Ø³Ù„Ø§Ù…", "hi": "Ø³Ù„Ø§Ù…",
    "goodbye": "Ø®Ø¯Ø§Ø­Ø§ÙØ¸", "bye": "Ø®Ø¯Ø§Ø­Ø§ÙØ¸",
    "please": "Ù„Ø·ÙØ§",
    "thank you": "Ù…ØªØ´Ú©Ø±Ù…", "thanks": "ØªØ´Ú©Ø±",
    "sorry": "Ù…ØªØ§Ø³ÙÙ…",
    "excuse me": "Ø¨Ø¨Ø®Ø´ÛŒØ¯",
    "yes": "Ø¨Ù„Ù‡", "no": "Ù†Ù‡",
    "ok": "Ø¨Ø§Ø´Ù‡", "okay": "Ø¨Ø§Ø´Ù‡",
    "this": "Ø§ÛŒÙ†", "that": "Ø¢Ù†",
    "these": "Ø§ÛŒÙ†Ù‡Ø§", "those": "Ø¢Ù†Ù‡Ø§",
    "here": "Ø§ÛŒÙ†Ø¬Ø§", "there": "Ø¢Ù†Ø¬Ø§",
    "now": "Ø§Ú©Ù†ÙˆÙ†", "then": "Ø³Ù¾Ø³",
    "today": "Ø§Ù…Ø±ÙˆØ²", "tomorrow": "ÙØ±Ø¯Ø§", "yesterday": "Ø¯ÛŒØ±ÙˆØ²",
    "later": "Ø¨Ø¹Ø¯Ø§",
    "a": "ÛŒÚ©", "an": "ÛŒÚ©", "the": "Ø­Ø±Ù ØªØ¹Ø±ÛŒÙ"
}

# -------------------- Part-of-Speech Map --------------------
POS_MAP = {
    
"i": "PRON", "you": "PRON", "he": "PRON", "she": "PRON", "it": "PRON",
    "we": "PRON", "they": "PRON", "me": "PRON", "him": "PRON", "her": "PRON",
    "us": "PRON", "them": "PRON", "my": "PRON", "your": "PRON", "his": "PRON",
    "our": "PRON", "their": "PRON",
    "am": "V_ACTION", "is": "V_ACTION", "are": "V_ACTION", "was": "V_ACTION", "were": "V_ACTION",
    "be": "V_ACTION", "say": "V_ACTION", "get": "V_ACTION", "make": "V_ACTION",
    "go": "V_ACTION", "see": "V_ACTION", "take": "V_ACTION", "come": "V_ACTION",
    "know": "V_ACTION", "think": "V_ACTION", "want": "V_ACTION", "love": "V_ACTION",
    "work": "V_ACTION", "read": "V_ACTION", "write": "V_ACTION", "run": "V_ACTION",
    "play": "V_ACTION", "feel": "V_ACTION", "give": "V_ACTION", "ask": "V_ACTION",
    "start": "V_ACTION", "stop": "V_ACTION", "live": "V_ACTION", "use": "V_ACTION",
    # FIX: Added 'hate', 'beat', 'kick', 'feeling' to V_ACTION
    "hate": "V_ACTION",
    "beat": "V_ACTION",
    "kick": "V_ACTION",
    "feeling": "V_ACTION",
}

def get_pos(word):
    return POS_MAP.get(word.lower(),'OTHER')



# -------------------- Training Phrases (Expanded and Improved) --------------------
training_phrases = [
    # Basic Positives/Negatives/Neutrals
    "how are you", "i am fine", "thank you", "good morning", "see you later",
    "i love food", "you are beautiful", "today is good day", "i am happy",
    "you are my friend", "i am tired", "are you hungry", "what is your name",
    "good night", "i am very sad", "i am very happy", "i read book",
    "i write with pen", "i drink water", "i run fast", "the car is big",
    "my house is small", "i am tired and hungry", "red car", "i want to go",
    "i have a car", "i live in city", "i feel good", "she is happy",
    "we live here", "they are ready",
    
    # Advanced Sentences (New Additions for better context)
    # Negatives
    "this is bad and disappointing", 
    "i am angry with the service",    
    "i hate everything about this",    
    "the food was not good",         
    "i don't like this product at all", 
    "i feel terrible right now",
    "that service was the worst i have ever seen", 
    "i am feeling so sad and angry", 
    "this looks so ugly",
    "i am totally exhausted and dumb", # Includes new harsh words
    "i want to beat and kick them", # Includes new harsh words
    
    # Positives
    "this is an awesome product",     
    "everything is absolutely great", 
    "i feel wonderful today",
    "i love spending time here",
    "you are the best friend ever",
    "i like playing with my new toy", # Includes new word 'toy'
    
    # Neutrals
    "i wish things were different but it is okay",   
    "i am not sure about this plan",  
    "the weather is very cold",       
    "the service was okay, nothing special", 
    "i need to buy a new car",
    "i am watching tv tonight",
]

# -------------------- AI-based Sentiment (NLP ML) --------------------
# Simple pseudo-labeled training for ML
positive_words = {"good", "happy", "love", "fine", "great", "awesome", "wonderful", "best"}
# FIX: Added 'ugly', 'worst', 'don't', 'dumb', 'exhausted' to capture harshness/negative state.
negative_words = {"sad", "angry", "bad", "hate", "tired", "hungry", "disappointing", "terrible", "ugly", "worst", "don't", "dumb", "exhausted"}

train_labels = []
for text in training_phrases:
    words = set(text.lower().split())
    pos_count = len(words & positive_words)
    neg_count = len(words & negative_words)
    if pos_count > neg_count:
        train_labels.append("Positive")
    elif neg_count > pos_count:
        train_labels.append("Negative")
    else:
        train_labels.append("Neutral")

# Train TF-IDF + Logistic Regression
vectorizer_sent = TfidfVectorizer()
X_train = vectorizer_sent.fit_transform(training_phrases)

# Logistic Regression with aggressive C (100.0) and class_weight='balanced' for better fitting sparse negative data.
ml_model_sent = LogisticRegression(max_iter=5000, class_weight='balanced', C=100.0)
ml_model_sent.fit(X_train, train_labels)

def ml_sentiment_predict(sentence):
    X_test = vectorizer_sent.transform([sentence])
    pred = ml_model_sent.predict(X_test)[0]
    proba = ml_model_sent.predict_proba(X_test).max()
    return f"{pred} ({int(proba*100)}% confidence)"


# -------------------- Translation & Reordering --------------------
def simple_translate_and_reorder(sentence, dictionary):
    words = re.findall(r"\b\w+\b", sentence.lower())
    original_words = re.findall(r"\b\w+\b", sentence)
    translated = [dictionary.get(w.lower(), w) for w in words]
    en_tags = [get_pos(w) for w in words]
    if en_tags and en_tags[0]=='PRON':
        action_verb_indices = [i for i,tag in enumerate(en_tags) if tag=='V_ACTION']
        if len(action_verb_indices)==1:
            verb_index = action_verb_indices[0]
            fa_before_verb = translated[:verb_index]
            fa_after_verb = translated[verb_index+1:]
            fa_verb = translated[verb_index]
            reordered_fa = fa_before_verb + fa_after_verb + [fa_verb]
            return " ".join(reordered_fa)
    return " ".join(translated)

# -------------------- AI-based Next Word Prediction (Bigram) --------------------
bigram_freq = defaultdict(Counter)
for phrase in training_phrases:
    words = phrase.lower().split()
    for i in range(len(words) - 1):
        bigram_freq[words[i]][words[i + 1]] += 1

def ml_next_word_predict(sentence, top_n=3):
    words = sentence.lower().split()
    if not words:
        return ""
    last_word = words[-1]
    next_words_counter = bigram_freq.get(last_word)
    if not next_words_counter:
        return ""
    # Return top N next words sorted by frequency
    most_common = next_words_counter.most_common(top_n)
    return ", ".join([word for word, _ in most_common])

# -------------------- Streamlit UI --------------------
st.set_page_config(page_title="English-Persian Translator", page_icon="ğŸ¤–", layout="centered")
st.title(" ğŸ—£ï¸ English â†’ Persian Translator")
st.markdown("---")

if "translation_history" not in st.session_state:
    st.session_state["translation_history"] = []

def clear_history():
    st.session_state["translation_history"] = []

col_buttons = st.columns([1, 4])
with col_buttons[0]:
    st.button("ğŸ—‘ï¸ Clear History", on_click=clear_history, use_container_width=True)

with st.container():
    if not st.session_state["translation_history"]:
        st.info("Start a conversation by typing a sentence below!")
    for item in st.session_state.translation_history[::-1]:
        with st.chat_message("user"):
            st.write(item['user_text'])
        with st.chat_message("translator", avatar="ğŸ¤–"):
            st.success(item['translation'])

user_input = st.chat_input("Type your English sentence here...")

if user_input:
    persian_reordered = simple_translate_and_reorder(user_input, dictionary)
    sentiment_ml = ml_sentiment_predict(user_input)
    suggested_ml = ml_next_word_predict(user_input)

    result = {
        "user_text": user_input,
        "translation": persian_reordered,
        "sentiment": sentiment_ml,
        "suggestions": suggested_ml
    }
    st.session_state.translation_history.insert(0, result)
    st.rerun()

if st.session_state.translation_history:
    st.subheader("ğŸ“Š Latest Translation Analysis")
    latest_result = st.session_state.translation_history[0]
    st.markdown(f"**Input analyzed:** *{latest_result['user_text']}*")
    col1, col2 = st.columns(2)
    with col1:
        st.info("**Persian Structure**")
        st.caption("SVO â†’ SOV correction applied.")
    with col2:
        st.warning("ğŸ§  **ML-based Sentiment**")
        st.metric(label="Mood", value=latest_result['sentiment'])
    if latest_result['suggestions']:
        st.markdown("---")
        st.code(f"ğŸ’¡ Next Word Prediction: {latest_result['suggestions']}", language='text')
